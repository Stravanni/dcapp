{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Rating Prediction with DC pipelines -- Demo application\n",
    "\n",
    "## Intro\n",
    "\n",
    "This notebook is ment to collect all the scripts and instructions for running the *Movie Rating Prediction* experiment.\n",
    "\n",
    "Besides the code here you will need:\n",
    "\n",
    "- Data Civilizer Studio\n",
    "- (if not integratedin the Studio) the deepER-lite docker image https://hub.docker.com/r/daqcri/deeper-lite/\n",
    "    - in this case, just attach a bash session to the running image and run the scripts (run.sh and run-pred.sh) from there\n",
    "\n",
    "### Goal\n",
    "The goal is to **predict movie ratings** of a generic audience (i.e., *imdb.com* users), given the **critic ratings** and other features (e.g., genre, year) gathered from *rogerebert.com* (a website collecting reviews by critics)\n",
    "\n",
    "### **For a summary of the results scroll to the end of this notebook**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Data sets\n",
    "The two employed data sets have the following characteristics:\n",
    "    \n",
    "|dataset|#records|notes|\n",
    "|:--: |:--:|:--:|\n",
    "|Roger Ebert (https://www.rogerebert.com) |3.5k|contains information about critic rating|\n",
    "|IMBD (https://www.imdb.com) |6.8k|contains information about audience rating|\n",
    "\n",
    "\n",
    "**Labeled data for DeepER**:\n",
    "\n",
    "For running DeepER, labeled data has been provided by manually labeling 370 manually pairs of records (200 of which are matches).\n",
    "\n",
    "(When trained, DeepER finds 350 matches).\n",
    "\n",
    "\n",
    "---\n",
    "Since the scope of the applicaiton is to try DC component, and since imputeDB can only impute numerical values, I selected the attribute year from *roger_ebert* and I randomly injected 20-30 \"?\" character (on record that I know having a match).\n",
    "\n",
    "Then, Fahes is employed to discover DMVs.\n",
    "\n",
    "---\n",
    "\n",
    "When using ImputeDB for imputing the data, call the rogererbert corresponding file `y_imputeDB.csv`; it will be used to substitute the DMVs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "base_path = './'\n",
    "path_in = base_path\n",
    "path_out = \"./\"\n",
    "\n",
    "path_roger = base_path + \"data_dump/roger_dump.csv\"\n",
    "path_imdb = base_path + \"data_dump/imdb_dump.csv\"\n",
    "lableled = base_path + \"labeled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(path_roger, encoding = \"ISO-8859-1\")\n",
    "df2 = pd.read_csv(path_imdb, encoding = \"ISO-8859-1\")\n",
    "\n",
    "df_labeled = pd.read_csv(lableled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = df1\n",
    "tmp2 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>year</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>critic_rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>pg_rating</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>3487</td>\n",
       "      <td>Red River</td>\n",
       "      <td>1948</td>\n",
       "      <td>Howard Hawks</td>\n",
       "      <td>John Wayne,Montgomery Clift,Joanne Dru Groot,W...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Action, Western</td>\n",
       "      <td>Rated NR</td>\n",
       "      <td>133 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id movie_name  year     directors  \\\n",
       "3487  3487  Red River  1948  Howard Hawks   \n",
       "\n",
       "                                                 actors  critic_rating  \\\n",
       "3487  John Wayne,Montgomery Clift,Joanne Dru Groot,W...            4.0   \n",
       "\n",
       "                genre pg_rating     duration  \n",
       "3487  Action, Western  Rated NR  133 minutes  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.id==3487]\n",
    "# Red River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>movie_rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>6882</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>Howard Hawks</td>\n",
       "      <td>Paul Muni, Ann Dvorak, Karen Morley</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>93 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id movie_name     directors                               actors  \\\n",
       "6882  6882   Scarface  Howard Hawks  Paul Muni, Ann Dvorak, Karen Morley   \n",
       "\n",
       "      movie_rating                 genre duration  \n",
       "6882           7.8  Action, Crime, Drama  93 min   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.id==6882]\n",
    "# Scarface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "colSet1 = set(df1.columns)\n",
    "colSet2 = set(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to use only the common attributes for DeepER**\n",
    "\n",
    "- while later, for the data enhancement demo, we are using all the attributes of the records that have matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'duration', 'actors', 'movie_name', 'genre', 'directors']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id', 'movie_name', 'actors', 'directors', 'duration', 'genre']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonCols = list(colSet1.intersection(colSet2))\n",
    "print(commonCols)\n",
    "colsDeepER = ['id',\n",
    " 'movie_name',\n",
    " 'actors',\n",
    " #'movie_rating',# this is not the same attrinbute (imdb users vs. critic); we will use that for train/test\n",
    " 'directors',\n",
    " 'duration',\n",
    " 'genre'\n",
    "]\n",
    "colsDeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these dataset are those to use for the prediction phase of DeepER\n",
    "\n",
    "df1_deeper = df1[colsDeepER]\n",
    "df1_deeper.to_csv(path_out+'roger_deeper_prediction.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=True)\n",
    "\n",
    "df2_deeper = df2[colsDeepER]\n",
    "df2_deeper.to_csv(path_out+'imdb_deeper_prediction.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the set of entities that have been labeled for  DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lableled_ids1 = set(df_labeled['id1'])\n",
    "lableled_ids2 = set(df_labeled['id2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "df1_deeper_trainint = df1_deeper[df1_deeper.id.isin(lableled_ids1)]\n",
    "df2_deeper_trainint = df2_deeper[df2_deeper.id.isin(lableled_ids2)]\n",
    "print(len(df1_deeper_trainint))\n",
    "print(len(df2_deeper_trainint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled_true = df_labeled[df_labeled['gold']==1][['id1','id2']]\n",
    "\n",
    "set1 = set(df_labled_true.id1)\n",
    "set2 = set(df_labled_true.id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(set1.difference(lableled_ids1))==0)\n",
    "print(len(set2.difference(lableled_ids2))==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labled_true.to_csv(path_out+'gt.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_deeper_train = df1_deeper[df1_deeper.id.isin(lableled_ids1)]\n",
    "df1_deeper_train.to_csv(path_out+'roger_deeper_train.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=True)\n",
    "\n",
    "df2_deeper_train = df2_deeper[df2_deeper.id.isin(lableled_ids2)]\n",
    "df2_deeper_train.to_csv(path_out+'imdb_deeper_train.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1_deeper_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to be performed with the Data Civilizer modules\n",
    "Now use DeepER:\n",
    "\n",
    "The following comments refer to deeper-lite, cloned from github. (Not sure how to set the parameter 0.5, I did runs with also other configurations)\n",
    "\n",
    "- train the model:\n",
    "`bash run.sh movies5_repeat roger_deeper_train.csv imdb_deeper_train.csv gt.csv 5 0.5`\n",
    "\n",
    "- find the matches:\n",
    "`bash run-pred.sh movies5_repeat roger_deeper_prediction imdb_deeper_prediction 5 C_ER 0 1 no`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"movies5/24Oct_forDeepER/\"\n",
    "#path_ds1 = path + \"dump/imdb_dump.csv\"\n",
    "#path_ds2 = path + \"dump/roger_dump.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_year = base_path + \"y_imputeDB.csv\" # imputeDB (year only)\n",
    "path_match_deeper = base_path + \"predictions_0.csv\"\n",
    "#path_match_deeper = base_path + \"predictions_blocking.csv\" ## DIFFERENT BLOCKING EMPLOYED\n",
    "#path_match_deeper = \"movies5/match_found_by_deeper.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Piepline mode\n",
    "'''\n",
    "mode = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each of the following \"mode\" is a different pipeline\"\n",
    "- mode0: set to null DMVs\n",
    "- mode1: do nothing\n",
    "- mode2: use imputed values\n",
    "\n",
    "**re-read the data when change mode, since the datafame might be modified by each of them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(path_roger, encoding = \"ISO-8859-1\")\n",
    "df2 = pd.read_csv(path_imdb, encoding = \"ISO-8859-1\")\n",
    "\n",
    "df_deeper_match = pd.read_csv(path_match_deeper)\n",
    "#len(df_deeper_match)\n",
    "#dpm1=df_deeper_match\n",
    "#dpm2=df_deeper_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "    df1=df1[~(df1.year==\"?\")]\n",
    "elif mode == 1:\n",
    "    #continue\n",
    "    df_y = pd.read_csv(path_year, encoding = \"ISO-8859-1\")\n",
    "elif mode==2:\n",
    "    df_y = pd.read_csv(path_year, encoding = \"ISO-8859-1\")\n",
    "    df1.year = df_y['roger_ebert3_y_nulls.year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two tables (using the metches)\n",
    "partial = pd.merge(df2, df_deeper_match, left_on = 'id', right_on = 'id2')\n",
    "df_ = pd.merge(df1, partial, left_on = 'id', right_on = 'id1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['id_x', 'movie_name_x', 'year', 'directors', 'aa',\n",
    "       'critic_rating', 'genre', 'pg_rating', 'duration', 'id_y',\n",
    "       'movie_name_y', 'directorss', 'actors', 'movie_rating', 'genres',\n",
    "       'dd', 'id1', 'id2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.columns=colnames\n",
    "df_join = df_.drop(['id1', 'id2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fueature selected\n",
    "cc = [\n",
    "    'critic_rating', # from roger\n",
    "    'pg_rating',\n",
    "    'year',\n",
    "    'duration',\n",
    "    'actors',\n",
    "    'movie_rating' # from imdb\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = df_join[cc]\n",
    "movies = movies.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies.drop('movie_rating',axis=1)\n",
    "Y = movies[['movie_rating']]\n",
    "\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4896973467886723"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.4745882],\n",
       "       [0.4745882, 1.       ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.corrcoef(movies['movie_rating'], movies['critic_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4745882"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4745882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.4745882],\n",
       "       [0.4745882, 1.       ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.corrcoef(movies['movie_rating'], movies['critic_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eperiments with blocking (candidate pair generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_res = list(df_join[\"movie_name_x\"].values)\n",
    "ny_res = list(df_join[\"movie_name_y\"].values)\n",
    "\n",
    "nx = list(df1[\"movie_name\"].values)\n",
    "ny = list(df2[\"movie_name\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "k1 = list(map(lambda x: \"\".join(x.lower().strip().translate(table).split()[0:2]), nx_res))\n",
    "k2 = list(map(lambda x: \"\".join(x.lower().strip().translate(table).split()[0:2]), ny_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = list(zip(k1,k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22jump 21jump\n",
      "21jump 22jump\n",
      "thebaadermeinhof thebaader\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for p in pp:\n",
    "    if p[0]!=p[1]:\n",
    "        counter+=1\n",
    "        print(p[0]+\" \"+p[1])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = list(map(lambda x: \"\".join(x.lower().strip().translate(table).split()[0:2]), nx))\n",
    "k2 = list(map(lambda x: \"\".join(x.lower().strip().translate(table).split()[0:2]), ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfk1 = df1\n",
    "dfk2 = df2\n",
    "\n",
    "dfk1['k'] = k1\n",
    "dfk2['k'] = k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockCandidates = pd.merge(dfk1, dfk2, left_on = 'k', right_on = 'k')\n",
    "candidates_blocking = blockCandidates[[\"id_x\",\"id_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_blocking.to_csv(path_out+'blocking_candidates.csv',sep=',',index=False, quoting = csv.QUOTE_NONNUMERIC, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2412"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates_blocking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation\n",
    "The initial **hypothesis** was to verify if there is a correlation between user rating and critic rating.\n",
    "\n",
    "The only way to do that is to perform entity resolution between the two datasets.\n",
    "\n",
    "#### results:\n",
    "- **Pearson correlatoin**: 0.47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (prediciton)\n",
    "\n",
    "- **Metrics**: r squared ([r^2](https://en.wikipedia.org/wiki/Coefficient_of_determination)) is employed for assessing the quality of the predictions.\n",
    "The ideal method reaches 1.\n",
    "\n",
    "- Train/Test: 75/25\n",
    "\n",
    "---\n",
    "\n",
    "**Results**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0lax\"></th>\n",
    "    <th class=\"tg-0lax\">Pipeline</th>\n",
    "    <th class=\"tg-0lax\">r^2</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">1</td>\n",
    "    <td class=\"tg-0lax\">DeepER</td>\n",
    "    <td class=\"tg-0lax\">0.18</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">Fahes(set null)+DeepER</td>\n",
    "    <td class=\"tg-0lax\">0.40</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">Fahes+ImputeDB+DeepER</td>\n",
    "    <td class=\"tg-0lax\">0.50</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpmSet1 = set(zip(list(dpm1.id1.values),list(dpm1.id2.values)))\n",
    "#dpmSet2 = set(zip(list(dpm2.id1.values),list(dpm2.id2.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
